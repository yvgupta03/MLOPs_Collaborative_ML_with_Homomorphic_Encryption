{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tenseal\n",
        "!pip install cryptography"
      ],
      "metadata": {
        "id": "-Ir6regdU-aV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "138ad884-3cb1-481b-eac5-7d0a36ee37ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tenseal\n",
            "  Downloading tenseal-0.3.14-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenseal\n",
            "Successfully installed tenseal-0.3.14\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.9/dist-packages (40.0.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/dist-packages (from cryptography) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.12->cryptography) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "import pickle\n",
        "import tenseal as ts\n",
        "import urllib3\n",
        "\n",
        "from cryptography.hazmat.backends import default_backend\n",
        "from cryptography.hazmat.primitives import serialization\n",
        "from cryptography.hazmat.primitives import hashes\n",
        "from cryptography.hazmat.primitives.asymmetric import padding\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import time"
      ],
      "metadata": {
        "id": "-SFQWSRyU-W1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_encryption_keys():\n",
        "  # read keys from remote server\n",
        "  http = urllib3.PoolManager()\n",
        "\n",
        "  bytes_private_key = http.request('GET', 'https://personal.utdallas.edu/~pxn210006/keys/private_key.pem')\n",
        "  bytes_public_key = http.request('GET', 'https://personal.utdallas.edu/~pxn210006/keys/public_key.pem')\n",
        "\n",
        "  private_key = serialization.load_pem_private_key(\n",
        "      bytes_private_key.data,\n",
        "      password=None,\n",
        "      backend=default_backend()\n",
        "  )\n",
        "\n",
        "  public_key = serialization.load_pem_public_key(\n",
        "      bytes_public_key.data,\n",
        "      backend=default_backend()\n",
        "  )\n",
        "\n",
        "  return private_key, public_key"
      ],
      "metadata": {
        "id": "Ddq4xIKIU-UW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decrypt_master_model(file_name, decrypted_model):\n",
        "  # Decrypting the model\n",
        "  input = open(decrypted_model, 'ab')\n",
        "\n",
        "  # get keys\n",
        "  private_key, public_key = get_encryption_keys()\n",
        "\n",
        "  with open(file_name, 'rb') as output:\n",
        "    while True:\n",
        "      encrypt = output.read(256)\n",
        "\n",
        "      if not encrypt:\n",
        "        break\n",
        "\n",
        "      original_message = private_key.decrypt(\n",
        "          encrypt,\n",
        "          padding.OAEP(\n",
        "              mgf=padding.MGF1(algorithm=hashes.SHA256()),\n",
        "              algorithm=hashes.SHA256(),\n",
        "              label=None\n",
        "          )\n",
        "      )\n",
        "\n",
        "      input.write(original_message)\n",
        "\n",
        "  input.close()"
      ],
      "metadata": {
        "id": "LSc3VMULU-Ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalization of dataframe data\n",
        "def normalize_df(df):\n",
        "  for column in df.columns:\n",
        "    df[column] = (df[column] - df[column].min()) / (df[column].max() - df[column].min())\n",
        "  return df\n",
        "\n",
        "from collections import Counter\n",
        "# handling outlier data in dataframe\n",
        "def outlier_detection(df, n, columns):\n",
        "    rows = []\n",
        "    will_drop_train = []\n",
        "    for col in columns:\n",
        "        Q1 = np.nanpercentile(df[col], 25)\n",
        "        Q3 = np.nanpercentile(df[col], 75)\n",
        "        IQR = Q3 - Q1\n",
        "        outlier_point = 1.5 * IQR\n",
        "        rows.extend(df[(df[col] < Q1 - outlier_point)|(df[col] > Q3 + outlier_point)].index)\n",
        "    for r, c in Counter(rows).items():\n",
        "        if c >= n: will_drop_train.append(r)\n",
        "    return will_drop_train\n",
        "\n",
        "def preprocess_data(csv_file, predict_flag=False):\n",
        "  df = pd.read_csv(csv_file) #passing address of csv file to create data frame\n",
        "\n",
        "  # renaming columns\n",
        "  df.rename(columns={'height(cm)':'height', 'weight(kg)':'weight','waist(cm)':'waist',\n",
        "                          'eyesight(left)':'eyesight_left', 'eyesight(right)':'eyesight_right',\n",
        "                          'hearing(left)':'hearing_left', 'hearing(right)':'hearing_right',\n",
        "                          'fasting blood sugar':'fasting_blood_sugar',  'Cholesterol':'cholesterol',\n",
        "                          'HDL':'hdl','LDL':'ldl','Urine protein':'urine_protein',\n",
        "                          'serum creatinine':'serum_creatinine', 'AST':'ast','ALT':'alt',\n",
        "                          'Gtp':'gtp', 'dental caries' : 'dental_caries'}, inplace=True)\n",
        "\n",
        "  #converting non-numeric columns to numeric data type\n",
        "  df['gender'] = df['gender'].str.replace('F','0')\n",
        "  df['gender'] = df['gender'].str.replace('M','1')\n",
        "  df['gender'] = pd.to_numeric(df['gender'])\n",
        "\n",
        "  df['tartar'] = df['tartar'].str.replace('N','0')\n",
        "  df['tartar'] = df['tartar'].str.replace('Y','1')\n",
        "  df['tartar'] = pd.to_numeric(df['tartar'])\n",
        "\n",
        "  df['oral'] = df['oral'].str.replace('N','0')\n",
        "  df['oral'] = df['oral'].str.replace('Y','1')\n",
        "  df['oral'] = pd.to_numeric(df['oral'])\n",
        "\n",
        "  #cleaning data by observation\n",
        "  df = df.drop(['ID'], axis=1)\n",
        "\n",
        "  # removing oral column due to skewed data\n",
        "  df = df.drop(\"oral\", axis='columns')\n",
        "\n",
        "  #handling outliers in df\n",
        "  will_drop_train = outlier_detection(df, 3, df.select_dtypes([\"float\", \"int\"]).columns)\n",
        "  df.drop(will_drop_train, inplace = True, axis = 0)\n",
        "\n",
        "  #creating x and y split where y is the resultant classification data\n",
        "  y=None\n",
        "  x = df[['height','weight','waist','hdl','ldl','serum_creatinine','alt','gtp','dental_caries','tartar','triglyceride','hemoglobin']]\n",
        "  if predict_flag==False:\n",
        "    y = df['smoking']\n",
        "\n",
        "  #normalizing x data to maintain the scale necessary for creation of model\n",
        "  x = normalize_df(x)\n",
        "\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "5lB7-4coU-Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(sgd_model, x_train, y_train, print_flag=False):\n",
        "  sgd_model.partial_fit(x_train, y_train, classes = np.unique(y_train))\n",
        "\n",
        "  if print_flag:\n",
        "    x_train_prediction = sgd_model.predict(x_train)\n",
        "    training_data_accuracy = accuracy_score(x_train_prediction, y_train)\n",
        "    print('Training data accuracy: ',training_data_accuracy)\n",
        "\n",
        "    x_test, y_test = preprocess_data('https://personal.utdallas.edu/~pxn210006/dataset/dataset_test.csv')\n",
        "    score = sgd_model.score(x_test, y_test)\n",
        "    print('New model accuracy on test data', score)\n",
        "\n",
        "def print_test_accuracy(sgd_model, input_csv_data):\n",
        "  x_in, y_in = preprocess_data(input_csv_data, predict_flag=True) #y_in is None since we are pre-processing for prediction\n",
        "  result = sgd_model.predict(x_in)\n",
        "  print('Result for input data ', result)\n",
        "\n",
        "  score = sgd_model.score(x_in, result)\n",
        "  print('Model accuracy on input data ', score)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "etrJIZR9VL6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encrypt_model_parameters(sgd_model, encrypted_model):\n",
        "  sgd_params = np.hstack((sgd_model.intercept_[:,None], sgd_model.coef_))\n",
        "\n",
        "  def context():\n",
        "    context = ts.context(ts.SCHEME_TYPE.CKKS, 8192, coeff_mod_bit_sizes=[60, 40, 40, 60])\n",
        "    context.global_scale = pow(2, 40)\n",
        "    context.generate_galois_keys()\n",
        "    return context\n",
        "\n",
        "  context = context()\n",
        "\n",
        "  sgd_params_encrypted = ts.ckks_tensor(context, sgd_params)\n",
        "  params_encrypted = sgd_params_encrypted.serialize()\n",
        "\n",
        "  with open('encrypted_model', 'wb') as file:\n",
        "    file.write(params_encrypted)\n",
        "\n",
        "  # encrypt the model\n",
        "  output = open(encrypted_model, 'ab')\n",
        "\n",
        "  # get keys\n",
        "  private_key, public_key = get_encryption_keys()\n",
        "\n",
        "  with open('encrypted_model', 'rb') as input:\n",
        "    while True:\n",
        "      msg = input.read(100)\n",
        "\n",
        "      if not msg:\n",
        "        break\n",
        "\n",
        "      encrypted = public_key.encrypt(\n",
        "          msg,\n",
        "          padding.OAEP(\n",
        "              mgf=padding.MGF1(algorithm=hashes.SHA256()),\n",
        "              algorithm=hashes.SHA256(),\n",
        "              label=None\n",
        "          )\n",
        "      )\n",
        "\n",
        "      output.write(encrypted)\n",
        "\n",
        "  output.close()"
      ],
      "metadata": {
        "id": "0y5hJzHZVL3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_consent():\n",
        "  x = input('Do you consent to use this data for improving the model? (Y/N) ')\n",
        "  x = x.lower()\n",
        "  if x==\"y\":\n",
        "    return True\n",
        "  elif x==\"n\":\n",
        "    return False\n",
        "  else:\n",
        "    print(\"Invalid option selected. Please try again and choose 'y' or 'n' \")\n",
        "    return get_consent()"
      ],
      "metadata": {
        "id": "fZLKMvOop2bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  # after receiving model from master\n",
        "  # decrypt the model\n",
        "  decrypt_master_model('master_model', 'decrypted_master_model')\n",
        "\n",
        "  # get orginal model back\n",
        "  sgd_model = pickle.load(open('decrypted_master_model', 'rb'))\n",
        "\n",
        "  # load and process data\n",
        "  dataset_link = 'https://personal.utdallas.edu/~pxn210006/dataset/dataset3.csv'\n",
        "  x_train, y_train = preprocess_data(dataset_link)\n",
        "\n",
        "  # train the model\n",
        "  train_model(sgd_model, x_train, y_train, True)\n",
        "\n",
        "  # encrypt the model\n",
        "  encrypt_model_parameters(sgd_model, 'worker_model')\n",
        "\n",
        "# main()"
      ],
      "metadata": {
        "id": "a-sYOvwkVL0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Worker node pickle file handling\n",
        "\n",
        "import os\n",
        "import shutil  # refer - https://www.geeksforgeeks.org/how-to-create-a-duplicate-file-of-an-existing-file-using-python/\n",
        "\n",
        "#active file\n",
        "act_file = \"active_worker_model\"\n",
        "\n",
        "#passive file\n",
        "pass_file = \"passive_master_model\"\n",
        "\n",
        "#file received from Master Node\n",
        "updated_file = \"master_model\"\n",
        "\n",
        "while True:\n",
        "  if act_file.isfile():\n",
        "\n",
        "    # after receiving model from master\n",
        "    # decrypt the model\n",
        "    temp=None\n",
        "    decrypt_master_model(pass_file, None)\n",
        "    #os.remove(pass_file)\n",
        "\n",
        "    #Using active file to get the orginal model back\n",
        "    m = pickle.load(open(pass_file, 'rb'))\n",
        "\n",
        "    #ask for input data file from user in csv format\n",
        "    in_file_csv = input(\"Provide input csv filepath: \")\n",
        "\n",
        "    #get user consent using input prompt\n",
        "    if get_consent():\n",
        "      # pre-process data\n",
        "      x, y = preprocess_data(in_file_csv)\n",
        "      a = train_model(m, x, y, print_flag=True) #train model using partial_fit on new data and print accuracy for this trained model\n",
        "\n",
        "      # encrypt the model\n",
        "      encrypt_model_parameters(a, 'worker_model')\n",
        "\n",
        "      #send model to Master\n",
        "      send_model(a)\n",
        "    else:\n",
        "      print_test_accuracy(m, in_file_csv) #print accuracy for this trained model\n",
        "\n",
        "    #check for updated model files from master\n",
        "    if pass_file.isfile():\n",
        "      os.remove(act_file)\n",
        "      act_file = shutil.copyfile(pass_file, act_file)\n",
        "      os.remove(pass_file)\n",
        "      print(\"Model update received from Master Node.\")\n",
        "\n",
        "  else:\n",
        "    print(\"Waiting for initial model...\")\n",
        "    time.sleep(10) # resume after 30 seconds"
      ],
      "metadata": {
        "id": "uh6epGqxjQGY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}